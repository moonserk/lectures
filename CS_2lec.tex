\documentclass[a4paper]{article}
\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{booktabs}
\usepackage{color,colortbl}
%\usepackage{amsmath}
%\usepackage{amsfonts}
%\usepackage{amssymb}
%\usepackage{makeidx}

\definecolor{darkishgreen}{RGB}{39,203,22}
\definecolor{LightCyan}{rgb}{0.88,1,1}
\definecolor{Gray}{gray}{0.9}
\definecolor{lightRed}{RGB}{230,170,150}
\definecolor{modRed}{RGB}{230,82,90}
\definecolor{strongRed}{RGB}{230,6,6}

\usepackage[english,russian]{babel}

\begin{document}

\section{Понятии о информации, ее измерение}

\subsection{Информация и данные}

Данные --- это совокупность сведений, зафиксированных на определенном носителе в форме, пригодной для постоянного хранения, передачи и обработки. Преобразование и обработка данных позволяет получить информацию.\\
Информация --- это результат преобразования и анализа данных. Отличие информации от данных состоит в том, что данные --- это фиксированные сведения о событиях и явлениях, которые хранятся на определенных носителях, а информация появляется в результате обработки данных при решении конкретных задач. Например, в базах данных хранятся различные данные, а по определенному запросу система управления базой данных выдает требуемую информацию.

 Применительно к компьютерной обработке данных под информацией понимают некоторую последовательность символических обозначений (букв, цифр, закодированных графических образов и звуков и т.п.), несущую смысловую нагрузку и представленную в понятном компьютеру виде. Каждый новый символ в такой последовательности символов увеличивает информационный объём сообщения.

\subsubsection{Операции с данными}

В ходе информационного процесса данные преобразуются из одного вида в другой. По мере развития НТП и общего усложнения связей в человеческом обществе трудозатраты на обработку данных неуклонно возрастают (постоянное усложнение условий управления производством и обществом + быстрые темпы появления и внедрения новых носителей/хранителей данных – увеличение объёма данных).

\begin{itemize}
\item Сбор – накопление данных с целью обеспечения достаточной полноты информации для принятия решения;

\item Формализаци – приведение данных, поступающих из разных источников, к одинаковой форме, чтобы сделать их сопоставимыми между собой, то есть повысить их уровень доступности;

\item Фильтрация – отсеивание «лишних» данных, в которых нет необходимости для принятия решений; при этом должен уменьшаться уровень «шума», а достоверность и адекватность данных должны возрастать;

\item Сортировка – упорядочение данных по заданному признаку с целью удобства использования; повышает доступность информации;

\item Группировка – объединение данных по заданному признаку с целью повышения удобства использования; повышает доступность информации;

\item Архиваци – организация хранения данных в удобной и легкодоступной форме; служит для снижения экономических затрат на хранение данных и повышает общую надежность информационного процесса в целом;

\item Защита – комплекс мер, направленных на предотвращение утраты, воспроизведение и модификации данных;

\item Транспортировка – прием и передача (доставка и поставка) данных между удаленными участниками информационного процесса; при этом источник данных в информатике принято называть сервером, а потребителя – клиентом;

\item Преобразование – перевод данных из одной формы в другую или из одной структуры в другую. Пример: изменение типа носителя; книги – бумага, электронная форма, микрофотоплёнка. Необходимость в многократном преобразовании данных возникает также при их транспортировке, особенно если она осуществляется средствами, не предназначенными для транспортировки данного вида данных.

\end{itemize}

\subsection{Свойства информации}

 При работе с информацией всегда имеются ее источник и потребитель (получатель). Для потребителя всегда очень важны свойства получаемой информации. Полезная информация уменьшает степень неопределенности у получателя и пополняет знания. Полезность информации относительна – кому-то полезна, а кому-то бесполезна. Данные становятся полезной информацией, если поступили своевременно, представляют интерес, новизну для решения практических задач. В противном случае данные бесполезны.

Можно привести немало разнообразных свойств информации. С точки зрения информатики наиболее важными представляются следующие свойства: адекватность, достоверность, полнота, актуальность и доступность, объективность информации.

\begin{itemize}
\item Адекватность информации – уровень соответствия создаваемого с помощью информации образа реальному объекту, процессу, явлению. Неадекватная информация может образовываться при создании новой информации на основе неполных или недостоверных данных. Неправильная информация – следствие предоставления неверных или искаженных сведений, ошибочной передачи, неправильно обработанных или ошибочных данных об объекте, событии или процессе. Однако и полные, и достоверные данные могут приводить к созданию неадекватной информации в случае применения к ним неадекватных методов. В реальной жизни человек вряд ли может рассчитывать на полную адекватность информации, так как всегда присутствует некоторая степень неопределенности. От степени адекватности информации реальному состоянию объекта или процесса зависит правильность принятия человеком решений. Адекватность информации может выражаться в трех формах: синтаксической, семантической и прагматической. Синтаксическая форма отражает формально-структурные характеристики и не затрагивает смысловое содержание информации. На синтаксическом уровне учитывается способ представления информации, скорость передачи информации и обработки, размеры кода представления информации. Рассматриваемую с этой синтаксической стороны информацию называют данными, так как при этом не имеет значения ее смысловая сторона.Семантическая форма отражает смысловое содержание информации. На этом уровне анализируются сведения, предоставляемые информацией, рассматриваются ее смысловые связи. Прагматический аспект отражает потребительскую сторону информации, ее соответствие цели управления, которая на основе этой информации реализуется. Он связан с ценностью, полезностью использования информации при выработке потребителем решения для достижения своей цели. С этой точки зрения анализируются потребительские свойства информации.

\item Достоверность информации – свойство отражать реально существующие объекты с необходимой точностью. Данные возникают в момент регистрации сигналов, но не все сигнал являются полезными – всегда присутствует какой-то уровень посторонних сигналов, в результате чего полезные данные сопровождаются определенным уровнем информационного шума. Информационный шум (информационный мусор) – данные и сведения, не несущие полезной информации, увеличивающие временные и прочие издержки пользователя при извлечении  и обработке информации. Если полезный сигнал зарегистрирован более четко, чем посторонние сигналы, достоверность информации может быть более высокой. При увеличении уровня шумов достоверность информации снижается. В этом случае для передачи того же количества информации требуется использовать либо больше данных, либо более сложные методы.Полнота информации характеризует качество информации и определяет достаточность данных для принятия решений или для создания новых данных на основе имеющихся. Неточная информация – недостаточные, неточные, неполные сведения об объекте, событии или процессе. Может использоваться для поиска решения задачи, по увеличивает вероятность неправильных выводов и поэтому требует уточнения, обновления данных.Чем полнее данные, тем шире диапазон методов, которые можно использовать, тем проще подобрать метод, вносящий минимум погрешностей в ход информационного процесса.

\item Актуальность информации – степень соответствия информации текущему моменту времени. Достоверная и адекватная, но устаревшая информация может приводить к ошибочным решениям. Необходимость поиска (или разработки) адекватного метода для работы с данными способна приводить к такой задержке в получении информации, что она становится неактуальной и ненужной.

\item Доступность информации – мера возможности получить ту или иную информацию. На степень доступности информации влияют одновременно как доступность данных, так и доступность адекватных методов для их интерпретации. Отсутствие доступа к данным или отсутствие адекватных методов обработки данных приводят к одинаковому результату: информация оказывается недоступной. Отсутствие адекватных методов для работы с данными во многих случаях приводит к применению неадекватных методов, в результате чего образуется неполная, неадекватная или недостоверная информация.

\item Объективность и субъективность информации. Понятие объективности информации является относительным. Более объективной принято считать ту информацию, в которую методы вносят меньший субъективный элемент. Так, в результате наблюдения фотоснимка природного объекта или явления образуется более объективная информация, чем в результате наблюдения рисунка того же объекта, выполненного человеком.

\end{itemize}

\subsection{Измерение информации}

Какое количество информации содержится, к примеру, в тексте романа 'Война и мир', в фресках Рафаэля или в генетическом коде человека? Ответа на эти вопросы наука не даёт и, по всей вероятности, даст не скоро. А возможно ли объективно измерить количество информации? Важнейшим результатом теории информации является вывод:

В определенных, весьма широких условиях можно пренебречь качественными особенностями информации, выразить её количество числом, а также сравнить количество информации, содержащейся в различных группах данных. В настоящее время получили распространение подходы к определению понятия 'количество информации', основанные на том, что информацию, содержащуюся в сообщении, можно нестрого трактовать в смысле её новизны или, иначе, уменьшения неопределённости наших знаний об объекте.
Так, американский инженер Р. Хартли (1928 г.) процесс получения информации рассматривает как выбор одного сообщения из конечного наперёд заданного множества из N равновероятных сообщений, а количество информации I, содержащееся в выбранном сообщении, определяет как двоичный логарифм N.
\begin{equation}
  I = \log_{2}N
\end{equation}
Допустим, нужно угадать одно число из набора чисел от единицы до ста. По формуле Хартли можно вычислить, какое количество информации для этого требуется: $I=\log_{2}100=6,644$. То есть сообщение о верно угаданном числе содержит количество информации, приблизительно равное 6,644 единиц информации.
Приведем другие примеры равновероятных сообщений:
\begin{enumerate}
\item при бросании монеты: 'выпала решка', 'выпал орел';
\item на странице книги: 'количество букв чётное', 'количество букв нечётное'.
\end{enumerate}

Определим теперь, являются ли равновероятными сообщения 'первой выйдет из дверей здания женщина' и 'первым выйдет из дверей здания мужчина'. Однозначно ответить на этот вопрос нельзя. Все зависит от того, о каком именно здании идет речь. Если это, например, станция метро, то вероятность выйти из дверей первым одинакова для мужчины и женщины, а если это военная казарма, то для мужчины эта вероятность значительно выше, чем для женщины. Для задач такого рода американский учёный Клод Шеннон предложил в 1948 г. другую формулу определения количества информации, учитывающую возможную неодинаковую вероятность сообщений в наборе.

\begin{equation}
  I = -\sum_{i=1}^{N}p_{i}\log_{2}p_{i}
\end{equation}

\begin{center}
  где, $p_{i}$ --- вероятность того, что именно i-е сообщение выделено в наборе из N сообщений.
\end{center}

Легко заметить, что если вероятности $p_{1}, \ldots , p_{N}$ равны, то каждая из них равна $1/N$, и формула Шеннона превращается в формулу Хартли.

Помимо двух рассмотренных подходов к определению количества информации, существуют и другие. Важно помнить, что любые теоретические результаты применимы лишь к определённому кругу случаев, очерченному первоначальными допущениями.

В качестве единицы информации условились принять один бит (англ. bit --- binary, digit --- двоичная цифра). Бит в теории информации --- количество информации, необходимое для различения двух равновероятных сообщений. А в вычислительной технике битом называют наименьшую 'порцию' памяти, необходимую для хранения одного из двух знаков '0' и '1', используемых для внутримашинного представления данных и команд.\\
Бит — слишком мелкая единица измерения. На практике чаще применяется более крупная единица — байт, равная восьми битам. Именно восемь битов требуется для того, чтобы закодировать любой из 256 символов алфавита клавиатуры компьютера (256 = $2^{8}$).

\begin{itemize}
  \item 1 слово = 2 байта = 16 бит
  \item 1  тетрада (нибл) = 1/2 байта = 4 бита
\end{itemize}

Широко используются также ещё более крупные производные единицы информации:
\begin{itemize}
  \item 1 Килобайт (Кбайт) = 1024 байт = $2^{10}$ байт,
  \item 1 Мегабайт (Мбайт) = 1024 Кбайт = $2^{20}$ байт,
  \item 1 Гигабайт (Гбайт) = 1024 Мбайт = $2^{30}$ байт.
\end{itemize}

В последнее время в связи с увеличением объёмов обрабатываемой информации входят в употребление такие производные единицы, как:
\begin{itemize}
  \item 1 Терабайт (Тбайт) = 1024 Гбайт = $2^{40}$ байт,
  \item 1 Петабайт (Пбайт) = 1024 Тбайт = $2^{50}$ байт,
  \item 1 Экабайт = $2^{64}$ байт.
\end{itemize}

За единицу информации можно было бы выбрать количество информации, необходимое для различения, например, десяти равновероятных сообщений. Это будет не двоичная (бит), а десятичная (дит) единица информации.

\end{document}
